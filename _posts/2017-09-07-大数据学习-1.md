---
layout: post
title: 大数据学习—1
date:   2017-09-07 09:06:52 +0800
categories: BigData
---
* TOC
{:toc}

# 1 hadoop生态体系概念理解

* HDFS：HDFS是一种分布式文件系统层，可对集群节点间的存储和复制进行协调。HDFS确保了无法避免的节点故障发生后数据依然可用，可将其用作数据来源，可用于存储中间态的处理结果，并可存储计算的最终结果。
* YARN：YARN是Yet Another Resource Negotiator（另一个资源管理器）的缩写，可充当Hadoop堆栈的集群协调组件。该组件负责协调并管理底层资源和调度作业的运行。通过充当集群资源的接口，YARN使得用户能在Hadoop集群中使用比以往的迭代方式运行更多类型的工作负载。
* MapReduce：MapReduce是Hadoop的原生批处理引擎。

批处理 
批处理模式中使用的数据集通常符合下列特征
- 有界：批处理数据集代表数据的有限集合
- 持久：数据通常始终存储在某种类型的持久存储位置中
- 大量：批处理操作通常是处理极为海量数据集的唯一方法

批处理非常适合需要访问全套记录才能完成的计算工作。例如在计算总数和平均数时，必须将数据集作为一个整体加以处理，而不能将其视作多条记录的集合。这些操作要求在计算进行过程中数据维持自己的状态。需要处理大量数据的任务通常最适合用批处理操作进行处理。无论直接从持久存储设备处理数据集，或首先将数据集载入内存，批处理系统在设计过程中就充分考虑了数据的量，可提供充足的处理资源。由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析。
大量数据的处理需要付出大量时间，因此批处理不适合对处理时间要求较高的场合。

批处理模式
Hadoop的处理功能来自MapReduce引擎。MapReduce的处理技术符合使用键值对的map、shuffle、reduce算法要求。基本处理过程包括：

* 从HDFS文件系统读取数据集
* 将数据集拆分成小块并分配给所有可用节点
* 针对每个节点上的数据子集进行计算（计算的中间态结果会重新写入HDFS）
* 重新分配中间态结果并按照键进行分组
* 通过对每个节点计算的结果进行汇总和组合对每个键的值进行“Reducing”
* 将计算而来的最终结果重新写入 HDFS

## 1-1 Hadoop开源项目、安装配置

官网教程 <https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html>

Hadoop cluster in one of the three supported modes:<br>
  Local (Standalone) Mode <br>
  Pseudo-Distributed Mode<br>
  Fully-Distributed Mode<br>

The project includes these modules:

* Hadoop Common: The common utilities that support the other Hadoop modules.
* Hadoop Distributed File System (HDFS™): A distributed file system that provides high-throughput access to application data.
* Hadoop YARN: A framework for job scheduling and cluster resource management.
* Hadoop MapReduce: A YARN-based system for parallel processing of large data sets.

一个HDFS集群主要由一个NameNode和很多个Datanode组成：Namenode管理文件系统的元数据，而Datanode存储了实际的数据

![](/resource/img/hdfsarchitecture.gif)


<https://hadoop.apache.org/docs/current/>

<http://www.powerxing.com/install-hadoop/>

----
此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。
----

## 1-2 MapReduce快速入门
### 1-2-1 wordcount例子
### 1-2-2 wordcount程序打包执行理解
## 1-3 Hadoop分布式文件系统 I/O
## 1-4 理解mapreduce原理
## 1-5 mapReduce系统开发
## 1-6 Hive仓库工具使用
## 1-7 Hbase 数据库使用
## 1-8 sqoop oozie 工具使用理解

# 2 spark生态体系概念理解
Apache Spark是一种包含流处理能力的下一代批处理框架。与Hadoop的MapReduce引擎基于各种相同原则开发而来的Spark主要侧重于通过完善的内存计算和处理优化机制加快批处理工作负载的运行速度。

Spark可作为独立集群部署（需要相应存储层的配合），或可与Hadoop集成并取代MapReduce引擎。

* 批处理模式
与MapReduce不同，Spark的数据处理工作全部在内存中进行，只在一开始将数据读入内存，以及将最终结果持久存储时需要与存储层交互。所有中间态的处理结果均存储在内存中。

虽然内存中处理方式可大幅改善性能，Spark在处理与磁盘有关的任务时速度也有很大提升，因为通过提前对整个任务集进行分析可以实现更完善的整体式优化。为此Spark可创建代表所需执行的全部操作，需要操作的数据，以及操作和数据之间关系的Directed Acyclic Graph（有向无环图），即DAG，借此处理器可以对任务进行更智能的协调。

为了实现内存中批计算，Spark会使用一种名为Resilient Distributed Dataset（弹性分布式数据集），即RDD的模型来处理数据。这是一种代表数据集，只位于内存中，永恒不变的结构。针对RDD执行的操作可生成新的RDD。每个RDD可通过世系（Lineage）回溯至父级RDD，并最终回溯至磁盘上的数据。Spark可通过RDD在无需将每个操作的结果写回磁盘的前提下实现容错。

流处理模式
流处理能力是由Spark Streaming实现的。Spark本身在设计上主要面向批处理工作负载，为了弥补引擎设计和流处理工作负载特征方面的差异，Spark实现了一种叫做微批（Micro-batch）*的概念。在具体策略方面该技术可以将数据流视作一系列非常小的“批”，借此即可通过批处理引擎的原生语义进行处理。

Spark Streaming会以亚秒级增量对流进行缓冲，随后这些缓冲会作为小规模的固定数据集进行批处理。这种方式的实际效果非常好，但相比真正的流处理框架在性能方面依然存在不足。

## 2-1 spark 部署运行
## 2-2 spark程序开发
## 2-3 spark 编程模型RDD开发
## 2-4 作业执行解析
### 2-4-1 RDD视图 DAG图
### 2-4-2 sparkSQL DataFrame
## 2-5 Spark Streaming 
## 2-6 Spark MLib 与机器学习
## 2-7 GraphX SparkR 
## 2-8 Spark 项目实战
### 2-8-1 大数据分析系统
### 2-8-2 系统资源分析平台
### 2-8-3 在Spark上训练LR模型
### 2-8-4 获取二级邻居关系图

# 3 storm生态体系概念理解
//TODO

# 4 区别

* 仅批处理框架：
Apache Hadoop
* 仅流处理框架：
Apache Storm
Apache Samza
* 混合框架：
Apache Spark
Apache Flink



## 4-2

